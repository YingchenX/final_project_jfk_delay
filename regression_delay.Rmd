---
title: "Regression_delay"
output: github_document
---


```{r setup, include=FALSE}
#Setup

library(tidyverse)
library(viridis)
library(modelr)
library(mgcv)
library(dplyr)
library(tidyr)
library(skimr)
library(plotly)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
set.seed(1)
```


```{r data wrangling, include=FALSE}
#Dataset
delay = read.csv("./tidied_data/delay.csv") %>% 
  janitor::clean_names() %>% filter(delay_minutes > 0)

h_weather = read.csv("./tidied_data/hourly_weather.csv") %>% 
  janitor::clean_names() 

#Check how many airlines
unique(delay$airline_name) #_7_ -> ok, keep

#Check how many destinations
unique(delay$destination_airport) #_66_ -> too many, remove

#Keep variables of interest and `date` for merge purpose (which will be removed later) 
## Clean dataset 'delay'
delay = delay %>% 
  rename(
    airline = airline_name,
    hour = scheduled_hour,
    delay = delay_minutes,
    carrierd = delay_carrier_minutes,
    extrmwd = delay_weather_minutes,
    nasd = delay_national_aviation_system_minutes,
    securityd = delay_security_minutes,
    latarrd = delay_late_aircraft_arrival_minutes) %>% 
  mutate(hour = as.numeric(hour),
         month = as.factor(month.abb[month]),
         airline = as.factor(airline)) %>% 
  select(airline, date, month, hour, delay, carrierd, extrmwd, nasd, securityd, latarrd)
  
#check 'NA'
sum(is.na(delay)) #_0_ -> good

## Clean dataset 'h_weather'
### About the measure of temperature: Since the dry bulb temperature is the ambient air temperature measured by regular thermometers, that is, the temperature often mentioned in our general weather forecast. Thus, we decide to use the variable `hourly_dry_bulb_temperature` to represent temperature.
h_weather = h_weather %>% 
  rename(
    temperature = hourly_dry_bulb_temperature,
    humidity = hourly_relative_humidity,
    visibility = hourly_visibility,
    wind_s = hourly_wind_speed) %>% 
  mutate(hour = as.numeric(hour),
         month = as.factor(month.abb[month])) %>% 
  select(date, month, hour, temperature, humidity, visibility, wind_s)

#check 'NA'
sum(is.na(h_weather)) #_0_ -> good

## Merge datasets 'delay' and 'hourly_weather'

raw_df = merge(x = delay, y = h_weather, by = c("date", "month", "hour"),
               all.x = TRUE) %>% 
  mutate(hour_c = cut(hour, breaks = c(4, 8, 13, 17, 24),
                      labels = c("morning","noon","afternoon","night"))) %>% 
  mutate(hour_c = as.factor(hour_c)) %>% 
  select(-hour)

#check 'NA'
sum(is.na(raw_df)) #_0_ -> good

###To this step, we have our raw dataset for doing association analysis. Since the outcome variable `delay` is a continuous variable, we would do linear regression. However, there might be too many variables so far (ignoring `date` we still got 12 potential predictors), so next step will be fitting the model.

### By intuition, I would set: `airline` -> categorical `month` -> categorical `hour` -> categorical (need further categorization); and for the rest -> continuous

## Inspections into the dataset

# Let's first check how each variable is roughly distributed.

### Dependent variable / outcome (continuous)
###See if our dependent variable `delay` follows a normal distribution.

#his_plot = raw_df %>% 
  #plot_ly(x = ~delay, 
   #type = "histogram", marker = list(color = 'rgb(255, 156, 128)'))

#his_plot %>% 
         #layout(
         #title = 'Distribution of hourly delay in time, 2021/11/1 to 2022/1/31',
         #xaxis = list(title = "Hourly delay in minutes", tickangle = -45),
         #yaxis = list(title = "Frequency"))

### No, our dependent variable `delay` is not normally distributed, but we dont want to remove those outliers since they are important to our analysis. -> It is okay because for linear regression, dependent variable does not have to be normally distributed. On the other hand, the model's residuals, do have to be normally distributed. 
```

# Overview

...

# Data description


Thus
...

# Step 1: Data Exploration

put it here OR put in the exploration page

## Check distribution of the outcome (continuous)

if not related to modeling, delete, or include it in the exploration page.

```{r}
his = raw_df %>% 
  plot_ly(x = ~delay, 
   type = "histogram", marker = list(color = 'rgb(255, 156, 128)'))

his %>% 
         layout(
         title = 'Distribution of hourly delay in time, 2021/11/1 to 2022/1/31',
         xaxis = list(title = "Hourly delay in minutes", tickangle = -45),
         yaxis = list(title = "Frequency"))
```

_Problems with the current outcome variable:_

* Skewness: This distribution is highly skewed, thus, we decided to keep only those delay time smaller than 60, which stands for bearable delay.

* Disagreement: The scale of the outcome variable (delay in time) is from 0 to +infinity, whereas the scale of the linear function is from -infinity to +infinity, we need to apply a log transformation to the outcome variable to make its scale agree with the model we proposed.

## Data Cleaning and Normalization (Log Transformation)

```{r}
log_df = raw_df %>% 
  filter(delay <= 60) %>% 
  mutate(log(as.data.frame(delay))) %>% 
  select(-date)

his = log_df %>% 
  plot_ly(x = ~delay, 
   type = "histogram", marker = list(color = 'rgb(255, 156, 128)'))

his %>% 
         layout(
         title = 'Distribution of log delay (minutes), 2021/11/1 to 2022/1/31',
         xaxis = list(title = "Log(delay)", tickangle = -45),
         yaxis = list(title = "Frequency"))
```

_Highlights:_

* Now, the distribution looks less skewed and the underlying scales for both side of equation will be in agreement.

## Explore the effect of potential predictors

_Motivation:_

To get a sense of the effect of each predictor.


_Plan:_

* For categorical variables:

We first produce boxplots to visualize the distribution of delay time across each categorical group. Then, we perform ANOVA to see if each group have the same average delay time. For those significant, we perform pairwise t-tests using Bonferroniâ€™s correction for the p-values to calculate pairwise differences between the delay time of each group.

* For continuous variables:

We first produce scatterplots to visualize the relationship between the continuous outcome and each continuous predictor to see if there is a linear relationship. We also calculate correlation coefficients for all continuous variables to measure the associations and detect if any strong linear correlations.


### Categorical predictors

```{r function for boxplot, include=FALSE}
box_cat = function(cat){
  
  box = log_df %>% 
  plot_ly(x = ~cat, y = ~delay, color = ~cat,
          type = 'box', colors = "viridis") %>%  
  layout(
    yaxis = list(title = "Log(Delay Time)"))

}
```


Airlines

```{r}
#boxplot
box_cat(log_df$airline) %>% 
  layout(xaxis = list(title = "Airline"))

#One-way ANOVA
aov(delay ~ airline, data = log_df) %>% summary()

#Pairwise t-tests (Bonferroni)
pairwise.t.test(log_df$delay, log_df$airline, p.adjust.method = "bonferroni")
```

_Highlights:_

* Since the overall p-value (<2e-16) is less than .05, this is an indication that each airline group does not have the same average delay time (in minutes).

* The adjusted p-value for the mean difference in delay time between JetBlue Airways _vs._ American Airlines and Delta Air Lines both are <2e-16, which suggests highly different.

* The adjusted p-value for the mean difference in delay time between American Airlines _vs._ Republic Airways is 1.6e-10, which also suggests highly different.


Months

```{r}
#boxplot
box_cat(log_df$month) %>% 
  layout(xaxis = list(title = "Month"))

#One-way ANOVA
aov(delay ~ month, data = log_df) %>% summary()

#Pairwise t-tests (Bonferroni)
pairwise.t.test(log_df$delay, log_df$month, p.adjust.method = "bonferroni")
```

_Highlights:_

* Since the overall p-value (1.17e-11) is less than .05, this is an indication that each month group does not have the same average delay time.

* The adjusted p-value for the mean difference in delay time between November, 2021 _vs._ December, 2021 is 0.00039, which suggests significantly different.

* The adjusted p-value for the mean difference in delay time between November, 2021 _vs._ January, 2022 is 3.9e-12, which suggests highly different.


Times of the day ("hour_c")

```{r}
#boxplot
box_cat(log_df$hour_c) %>% 
  layout(xaxis = list(title = "Times of the day"))

#One-way ANOVA
aov(delay ~ hour_c, data = log_df) %>% summary()

#Pairwise t-tests (Bonferroni)
pairwise.t.test(log_df$delay, log_df$hour_c, p.adjust.method = "bonferroni")
```

_Highlights:_

* Since the overall p-value (<2e-16) is less than .05, this is an indication that each hour group does not have the same average delay time.

* The adjusted p-value for the mean difference in delay time between morning _vs._ night is <2e-16, which suggests highly different.

* The adjusted p-value for the mean difference in delay time between noon _vs._ night is 1.4e-07, which also suggests highly different.


### Continuous predictors

```{r function for scatterplot, include=FALSE}
scat_con = function(con){
  
  scat = log_df %>%
  plot_ly(x = ~con, y = ~delay,
          type = 'scatter', mode = 'markers', alpha = .5) %>% 
    layout(
      yaxis = list(title = "Log(Delay Time)"))
}
```


Carrier Delay

```{r}
scat_con(log_df$carrierd) %>% 
  layout(xaxis = list(title = "Carrier Delay (minutes)"))
```


Extreme Weather Delay

```{r}
scat_con(log_df$extrmwd) %>% 
  layout(xaxis = list(title = "Extreme Weather Delay (minutes)"))
```


Late Arrival Delay

```{r}
scat_con(log_df$latarrd) %>% 
  layout(xaxis = list(title = "Late Arrival Delay (minutes)"))
```


NAS Delay

```{r}
scat_con(log_df$nasd) %>% 
  layout(xaxis = list(title = "NAS Delay (minutes)"))
```


Security Delay

```{r}
scat_con(log_df$securityd) %>% 
  layout(xaxis = list(title = "Security Delay (minutes)"))
```


Temperature

```{r}
scat_con(log_df$temperature) %>% 
  layout(xaxis = list(title = "Temperature"))
```


Humidity

```{r}
scat_con(log_df$humidity) %>% 
  layout(xaxis = list(title = "Humidity"))
```


Visibility

```{r}
scat_con(log_df$visibility) %>% 
  layout(xaxis = list(title = "Visibility"))
```


Wind Speed

```{r}
scat_con(log_df$wind_s) %>% 
  layout(xaxis = list(title = "Wind Speed"))
```


Pearson correlation 

```{r}
cor_po = log_df %>% 
  select(-airline, -month, -hour_c) %>% 
  cor(y = log_df$delay, x = ., method = c("pearson", "kendall", "spearman")) 

round(cor_po, 2)
```

_Highlights:_
 
* The Pearson correlation coefficient for the relationships between delay time and carrier delay is also greater than .50, which suggests potential linear association between the two.


# Step 2: Model fitting

_Motivation:_

To build a linear model for predicting the delay in time

_Plan:_

We proposed 2 rationales for modeling:

* Rationale 1 (Model 1):

According to the result from Step 1, we get a sense of what predictors should be included in the linear regression model. They are `airline`, `month`, `times in a day` (aka. `hour_c`), `carrier delay` (aka. `carrierd`), `Extreme Weather Delay` (aka. `extrmwd`), `security delayand` (aka. `securityd`), and `late arrival delay` (aka. `latarrd`).

* Rationale 2 (Model 2):

Given the large sample size (n=8617), we include all predictors of interests into the linear regression model, while ignoring the results from any hypothesis testing. 


## Fitting Model 1

Before fitting the linear model with these 7 predictors, let's check their independence using correlation to filter out highly correlated variables.

### Check collinearity

```{r}
cor_1 = log_df %>% 
  select(airline, month, hour_c, carrierd, latarrd, extrmwd, securityd) %>% 
  mutate(
    airline = as.numeric(airline),
    month = as.numeric(month),
    hour_c = as.numeric(hour_c)
    ) %>% 
  rename(
     "carrier delay" = carrierd,
     "late arrival delay" = latarrd,
    "times in a day" = hour_c) %>% 
  cor(method = c("pearson", "kendall", "spearman"))

round(cor_1, 2)

color = colorRampPalette(c("Blue", "White", "Red"))(20)
heatmap(x = cor_1, col = color, symm = TRUE)
```

_Highlights:_

* All predictors are highly independent to each other.

As we see above, independence assumption is met and thus we can add all these 7 predictors into to linear regression model.

### Model 1, without interaction

```{r}
lm_1 = lm(delay ~ airline + month + hour_c + carrierd + latarrd + extrmwd + securityd, data = log_df)
broom::glance(lm_1) %>% select(statistic, p.value, df) %>% mutate(p.value = recode(p.value, '0' = '<2.2e-16'))
```

_Highlights:_ 

* The F-value is 402 (very large) with p-value < 2.2e-16 (very small), which suggests that this regression model is statistically significant.


## Fitting Model 2


### Model 2, without interaction

```{r}
lm_2 = lm(delay ~ ., data = log_df)
broom::glance(lm_2) %>% select(statistic, p.value, df) %>% mutate(p.value = recode(p.value, '0' = '<2.2e-16'))
```

_Highlights:_ 

* The F-value is 308 (very large) with p-value < 2.2e-16 (very small), which suggests that this regression model is also statistically significant.


## Interactions and Model Comparison

From the previous exploration steps focusing on interactions, we further hypothesize 3 interaction terms ("Temperature * Month", "Carrier * Airline", "Month * Airline) that could be potentially added into the above model to enhance its predicting power.

To examine if the addition of interaction terms is necessary, we have 4 linear models to be compared, they are:

\ Model 1. delay ~ airline + month + hour_c + carrierd + latarrd + extrmwd + securityd

\ Model 2. delay ~ .

\ Model 3. delay ~ airline + month + hour_c + carrierd + latarrd + extrmwd + securityd + temperature + temperature * month + carrierd * airline + month * airline, by assuming an interaction between temperature and month, we need to include both variable into the model as well.

\ Model 4. delay ~ . + temperature * month + carrierd * airline + month * airline


### Cross-validation

```{r}
set.seed(123)

# Cross Validation
cv_df =
  crossv_mc(log_df, 100) %>% 
  mutate(train = map(train, as_tibble),
         test = map(test, as_tibble)) %>% 
  mutate(
    model1 = map(train, ~lm(delay ~ airline + month + hour_c + carrierd + latarrd + extrmwd + securityd, data = .x)),
    model2 = map(train, ~lm(delay ~ ., data = .x)),
    model3 = map(train, ~lm(delay ~ airline + month + hour_c + carrierd + latarrd + extrmwd + securityd + temperature + temperature * month + carrierd * airline + month * airline, data = .x)),
    model4 = map(train, ~lm(delay ~ . + temperature * month + carrierd * airline + month * airline, data = .x))) %>% 
  mutate(rmse_model1 = map2_dbl(model1, test, ~rmse(model = .x, data = .y)),
         rmse_model2 = map2_dbl(model2, test, ~rmse(model = .x, data = .y)),
         rmse_model3 = map2_dbl(model3, test, ~rmse(model = .x, data = .y)),
         rmse_model4 = map2_dbl(model4, test, ~rmse(model = .x, data = .y)))

cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin() +
  labs(x = "Model", y = "Root Mean Square Error (RMSE)",
       title = "Model Comparison of the Cross-Validated Prediction Error") +
  scale_x_discrete(labels = c("Model 1", "Model 2", "Model 3", "Model 4"))
```

_Highlights:_ 

* The RMSE for all 4 models are below 1, suggesting an accurate prediction.

* On the RMSE scale, there is not much difference between the 4 models, so we will choose model 1 for parsimony.


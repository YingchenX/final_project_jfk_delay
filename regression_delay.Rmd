---
title: "Predictive Modeling"
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
#Setup

library(tidyverse)
library(viridis)
library(modelr)
library(mgcv)
library(dplyr)
library(tidyr)
library(plotly)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
set.seed(1)
```


```{r data wrangling, include=FALSE}
#Dataset
delay = read.csv("./tidied_data/delay.csv") %>% 
  janitor::clean_names() %>% filter(delay_minutes > 0)

h_weather = read.csv("./tidied_data/hourly_weather.csv") %>% 
  janitor::clean_names() 

#Check how many airlines
unique(delay$airline_name) #_7_ -> ok, keep

#Check how many destinations
unique(delay$destination_airport) #_66_ -> too many, remove

#Keep variables of interest and `date` for merge purpose (which will be removed later) 
## Clean dataset 'delay'
delay = delay %>% 
  rename(
    airline = airline_name,
    hour = scheduled_hour,
    delay = delay_minutes,
    carrierd = delay_carrier_minutes,
    extrmwd = delay_weather_minutes,
    nasd = delay_national_aviation_system_minutes,
    securityd = delay_security_minutes,
    latarrd = delay_late_aircraft_arrival_minutes) %>% 
  mutate(hour = as.numeric(hour),
         month = as.factor(month.abb[month]),
         airline = as.factor(airline)) %>% 
  select(airline, date, month, hour, delay, carrierd, extrmwd, nasd, securityd, latarrd)
  
#check 'NA'
sum(is.na(delay)) #_0_ -> good

## Clean dataset 'h_weather'
### About the measure of temperature: Since the dry bulb temperature is the ambient air temperature measured by regular thermometers, that is, the temperature often mentioned in our general weather forecast. Thus, we decide to use the variable `hourly_dry_bulb_temperature` to represent temperature.
h_weather = h_weather %>% 
  rename(
    temperature = hourly_dry_bulb_temperature,
    humidity = hourly_relative_humidity,
    visibility = hourly_visibility,
    wind_s = hourly_wind_speed) %>% 
  mutate(hour = as.numeric(hour),
         month = as.factor(month.abb[month])) %>% 
  select(date, month, hour, temperature, humidity, visibility, wind_s)

#check 'NA'
sum(is.na(h_weather)) #_0_ -> good

## Merge datasets 'delay' and 'hourly_weather'

raw_df = merge(x = delay, y = h_weather, by = c("date", "month", "hour"),
               all.x = TRUE) %>% 
  mutate(hour_c = cut(hour, breaks = c(4, 8, 13, 17, 24),
                      labels = c("morning","noon","afternoon","night"))) %>% 
  mutate(hour_c = as.factor(hour_c)) %>% 
  select(-hour)

#check 'NA'
sum(is.na(raw_df)) #_0_ -> good

```

<br>

# Overview

From the previous data exploration and visualization, we found some interesting trend worthy of further analysis and some independent variables could be good in predicting the possible outcome. Thus, we decided to imply the concept of linear regression model here to build a predictive model for delay time since the outcome is continuous.

<br>

# Variable Description

* Dependent variable of interest: hourly delay time (in minutes)

* Independent variables of interest: 

  * Categorical: airlines, months, time of the day

  * Continuous: carrier delay time, extreme weather delay time, late arrival delay time, NAS delay time, security delay time, temperature, humidity, visibility, wind speed

<br>

# Step 1: Data Exploration

<br>

## Data normalization

<br>

### check distribution of the outcome (continuous)

```{r}
his = raw_df %>% 
  plot_ly(x = ~delay, 
   type = "histogram", marker = list(color = 'rgb(255, 156, 128)'))

his %>% 
         layout(
         title = 'Distribution of hourly delay in time, 2021/11/1 to 2022/1/31',
         xaxis = list(title = "Hourly delay in minutes", tickangle = -45),
         yaxis = list(title = "Frequency"))
```

_Problems with the current outcome variable:_

* Skewness: This distribution is highly skewed, thus, we decided to keep only those delay time smaller than 60, which stands for bearable delay.

* Disagreement: The scale of the outcome variable (delay in time) is from 0 to +infinity, whereas the scale of the linear function is from -infinity to +infinity, we need to apply a log transformation to the outcome variable to make its scale agree with the model we proposed.

<br>

### data cleaning and log transformation

```{r}
log_df = raw_df %>% 
  filter(delay <= 60) %>% 
  mutate(log(as.data.frame(delay))) %>% 
  select(-date)

his = log_df %>% 
  plot_ly(x = ~delay, 
   type = "histogram", marker = list(color = 'rgb(255, 156, 128)'))

his %>% 
         layout(
         title = 'Distribution of log delay, 2021/11/1 to 2022/1/31',
         xaxis = list(title = "Log(delay)", tickangle = -45),
         yaxis = list(title = "Frequency"))
```

**Highlights:**

* Now, the distribution looks less skewed and the underlying scales for both side of equation will be in agreement.

<br>

## Effect of potential predictors


**Motivation:**

To get a sense of the effect of each predictor.


**Plan:**

* For categorical variables:

We first produce boxplots to visualize the distribution of delay time across each categorical group. Then, we perform ANOVA to see if each group have the same average delay time. For those significant, we perform pairwise t-tests using Bonferroniâ€™s correction for the p-values to calculate pairwise differences between the delay time of each group.

* For continuous variables:

We first produce scatterplots to visualize the relationship between the continuous outcome and each continuous predictor to see if there is a linear relationship. We also calculate correlation coefficients for all continuous variables to measure the associations and detect if any strong linear correlations.

<br>

### categorical predictors

```{r function for boxplot, include=FALSE}
box_cat = function(cat){
  
  box = log_df %>% 
  plot_ly(x = ~cat, y = ~delay, color = ~cat,
          type = 'box', colors = "viridis") %>%  
  layout(
    yaxis = list(title = "Log(Delay Time)"))

}
```

<br>

*Airlines*

```{r}
#boxplot
box_cat(log_df$airline) %>% 
  layout(xaxis = list(title = "Airline"))

#One-way ANOVA
aov(delay ~ airline, data = log_df) %>% summary()

#Pairwise t-tests (Bonferroni)
pairwise.t.test(log_df$delay, log_df$airline, p.adjust.method = "bonferroni")
```

**Highlights:**

* Since the overall p-value (<2e-16) is less than .05, this is an indication that each airline group does not have the same average delay time (in minutes).

* The adjusted p-value for the mean difference in delay time between JetBlue Airways _vs._ American Airlines and Delta Air Lines both are <2e-16, which suggests highly different.

* The adjusted p-value for the mean difference in delay time between American Airlines _vs._ Republic Airways is 1.6e-10, which also suggests highly different.

<br>

*Months*

```{r}
#boxplot
box_cat(log_df$month) %>% 
  layout(xaxis = list(title = "Month"))

#One-way ANOVA
aov(delay ~ month, data = log_df) %>% summary()

#Pairwise t-tests (Bonferroni)
pairwise.t.test(log_df$delay, log_df$month, p.adjust.method = "bonferroni")
```

**Highlights:**

* Since the overall p-value (1.17e-11) is less than .05, this is an indication that each month group does not have the same average delay time.

* The adjusted p-value for the mean difference in delay time between November, 2021 _vs._ December, 2021 is 0.00039, which suggests significantly different.

* The adjusted p-value for the mean difference in delay time between November, 2021 _vs._ January, 2022 is 3.9e-12, which suggests highly different.

<br>

*Times of the day ("hour_c")*

```{r}
#boxplot
box_cat(log_df$hour_c) %>% 
  layout(xaxis = list(title = "Times of the day"))

#One-way ANOVA
aov(delay ~ hour_c, data = log_df) %>% summary()

#Pairwise t-tests (Bonferroni)
pairwise.t.test(log_df$delay, log_df$hour_c, p.adjust.method = "bonferroni")
```

**Highlights:**

* Since the overall p-value (<2e-16) is less than .05, this is an indication that each hour group does not have the same average delay time.

* The adjusted p-value for the mean difference in delay time between morning _vs._ night is <2e-16, which suggests highly different.

* The adjusted p-value for the mean difference in delay time between noon _vs._ night is 1.4e-07, which also suggests highly different.

<br>


### continuous predictors

```{r function for scatterplot, include=FALSE}
scat_con = function(con){
  
  scat = log_df %>%
  plot_ly(x = ~con, y = ~delay,
          type = 'scatter', mode = 'markers', alpha = .5) %>% 
    layout(
      yaxis = list(title = "Log(Delay Time)"))
}
```

<br>

*Carrier Delay*

```{r}
scat_con(log_df$carrierd) %>% 
  layout(xaxis = list(title = "Carrier Delay (minutes)"))
```

<br>

*Extreme Weather Delay*

```{r}
scat_con(log_df$extrmwd) %>% 
  layout(xaxis = list(title = "Extreme Weather Delay (minutes)"))
```

<br>

*Late Arrival Delay*

```{r}
scat_con(log_df$latarrd) %>% 
  layout(xaxis = list(title = "Late Arrival Delay (minutes)"))
```

<br>

*NAS Delay*

```{r}
scat_con(log_df$nasd) %>% 
  layout(xaxis = list(title = "NAS Delay (minutes)"))
```

<br>

*Security Delay*

```{r}
scat_con(log_df$securityd) %>% 
  layout(xaxis = list(title = "Security Delay (minutes)"))
```

<br>

*Temperature*

```{r}
scat_con(log_df$temperature) %>% 
  layout(xaxis = list(title = "Temperature"))
```

<br>

*Humidity*

```{r}
scat_con(log_df$humidity) %>% 
  layout(xaxis = list(title = "Humidity"))
```

<br>

*Visibility*

```{r}
scat_con(log_df$visibility) %>% 
  layout(xaxis = list(title = "Visibility"))
```

<br>

*Wind Speed*

```{r}
scat_con(log_df$wind_s) %>% 
  layout(xaxis = list(title = "Wind Speed"))
```

<br>

#### Pearson correlation 

```{r}
cor_po = log_df %>% 
  select(-airline, -month, -hour_c) %>% 
  cor(y = log_df$delay, x = ., method = c("pearson", "kendall", "spearman")) 

round(cor_po, 2)
```

**Highlights:**
 
* The Pearson correlation coefficient for the relationships between delay time and carrier delay is also greater than .50, which suggests potential linear association between the two.

<br>

# Step 2: Model Fitting

**Motivation:**

To build a linear model for predicting the delay in time

**Plan:**

We proposed 2 rationales for modeling:

* Rationale 1 (Model 1):

According to the result from Step 1, we get a sense of what predictors should be included in the linear regression model. They are `airline`, `month`, `times in a day` (aka. `hour_c`), `carrier delay` (aka. `carrierd`), `Extreme Weather Delay` (aka. `extrmwd`), `security delayand` (aka. `securityd`), and `late arrival delay` (aka. `latarrd`).

* Rationale 2 (Model 2):

Given the large sample size (n=8617), we include all predictors of interests into the linear regression model, while ignoring the results from any hypothesis testing. 

<br>

## Fitting model 1

Before fitting the linear model with these 7 predictors, let's check their independence using correlation to filter out highly correlated variables.

<br>

### check collinearity

```{r}
cor_1 = log_df %>% 
  select(airline, month, hour_c, carrierd, latarrd, extrmwd, securityd) %>% 
  mutate(
    airline = as.numeric(airline),
    month = as.numeric(month),
    hour_c = as.numeric(hour_c)
    ) %>% 
  rename(
     "carrier delay" = carrierd,
     "late arrival delay" = latarrd,
    "times in a day" = hour_c) %>% 
  cor(method = c("pearson", "kendall", "spearman"))

round(cor_1, 2)

color = colorRampPalette(c("Blue", "White", "Red"))(20)
heatmap(x = cor_1, col = color, symm = TRUE)
```

**Highlights:**

* All predictors are highly independent to each other.

As we see above, independence assumption is met and thus we can add all these 7 predictors into to linear regression model.

<br>

### model 1, without interaction

```{r}
lm_1 = lm(delay ~ airline + month + hour_c + carrierd + latarrd + extrmwd + securityd, data = log_df)
broom::glance(lm_1) %>% select(statistic, p.value, df) %>% mutate(p.value = recode(p.value, '0' = '<2.2e-16'))
```

**Highlights:** 

* The F-value is 402 (very large) with p-value < 2.2e-16 (very small), which suggests that this regression model is statistically significant.

<br>


## Fitting model 2

<br>

### model 2, without interaction

```{r}
lm_2 = lm(delay ~ ., data = log_df)
broom::glance(lm_2) %>% select(statistic, p.value, df) %>% mutate(p.value = recode(p.value, '0' = '<2.2e-16'))
```

**Highlights:** 

* The F-value is 308 (very large) with p-value < 2.2e-16 (very small), which suggests that this regression model is also statistically significant.

<br>

## Interactions

From the previous exploration steps focusing on interactions, we further hypothesize 3 interaction terms ("Temperature * Month", "Carrier * Airline", "Month * Airline) that could be potentially added into the above model to enhance its predicting power.

<br>

## Model comparison

To examine if the addition of interaction terms is necessary, we have 4 linear models to be compared, they are:

\ Model 1. delay ~ airline + month + hour_c + carrierd + latarrd + extrmwd + securityd

\ Model 2. delay ~ .

\ Model 3. delay ~ airline + month + hour_c + carrierd + latarrd + extrmwd + securityd + temperature + temperature * month + carrierd * airline + month * airline, by assuming an interaction between temperature and month, we need to include both variable into the model as well.

\ Model 4. delay ~ . + temperature * month + carrierd * airline + month * airline

<br>

### cross-validation

```{r}
set.seed(123)

# Cross Validation
cv_df =
  crossv_mc(log_df, 100) %>% 
  mutate(train = map(train, as_tibble),
         test = map(test, as_tibble)) %>% 
  mutate(
    model1 = map(train, ~lm(delay ~ airline + month + hour_c + carrierd + latarrd + extrmwd + securityd, data = .x)),
    model2 = map(train, ~lm(delay ~ ., data = .x)),
    model3 = map(train, ~lm(delay ~ airline + month + hour_c + carrierd + latarrd + extrmwd + securityd + temperature + temperature * month + carrierd * airline + month * airline, data = .x)),
    model4 = map(train, ~lm(delay ~ . + temperature * month + carrierd * airline + month * airline, data = .x))) %>% 
  mutate(rmse_model1 = map2_dbl(model1, test, ~rmse(model = .x, data = .y)),
         rmse_model2 = map2_dbl(model2, test, ~rmse(model = .x, data = .y)),
         rmse_model3 = map2_dbl(model3, test, ~rmse(model = .x, data = .y)),
         rmse_model4 = map2_dbl(model4, test, ~rmse(model = .x, data = .y)))

cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin() +
  labs(x = "Model", y = "Root Mean Square Error (RMSE)",
       title = "Model Comparison of the Cross-Validated Prediction Error") +
  scale_x_discrete(labels = c("Model 1", "Model 2", "Model 3", "Model 4"))
```

**Highlights:** 

* The RMSE for all 4 models are below 1, suggesting an accurate prediction.

* On the RMSE scale, there is not much difference between the 4 models, so we will choose model 1 for parsimony.


<br>


# Conclusion and Discussion


